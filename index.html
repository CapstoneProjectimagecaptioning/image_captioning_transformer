<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Image Captioning Project</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

    <header>
        <div class="container">
            <h1>üñºÔ∏è AI-Powered Image Captioning üß†</h1>
            <p>Explore how Transformers revolutionize Image Captioning!</p>
            <a href="#learn-more" class="btn">Learn More</a>
        </div>
    </header>

    <section id="intro" class="section">
        <div class="container">
            <h2>What is Image Captioning?</h2>
            <p>
                Image Captioning is the process of generating textual descriptions from images using artificial intelligence. By training transformer-based models, we can now automatically generate captions that are accurate, descriptive, and human-like.
            </p>
            <a href="#models" class="btn">Discover the Models</a>
        </div>
    </section>

    <section id="models" class="section">
        <div class="container">
            <h2>Models Used in the Project</h2>
            <div class="model-box">
                <h3>üß† BLIP - Bootstrapped Language-Image Pretraining</h3>
                <p>
                    BLIP is a state-of-the-art transformer model specifically designed for vision-language tasks. It learns from images and generates meaningful captions by bootstrapping the learning process.
                </p>
                <button class="btn" onclick="showMore('blip')">Learn More</button>
                <p id="blip" class="hidden-text">BLIP excels at generating accurate captions by analyzing both the image features and the language patterns within the data.</p>
            </div>
            <div class="model-box">
                <h3>üì∑ Vision Transformer (ViT)</h3>
                <p>
                    ViT is a powerful transformer architecture that processes images like patches, treating them as sequences. This model helps improve the visual understanding for caption generation.
                </p>
                <button class="btn" onclick="showMore('vit')">Learn More</button>
                <p id="vit" class="hidden-text">ViT focuses on high-dimensional image processing, enabling a deeper comprehension of complex images for more precise captions.</p>
            </div>
        </div>
    </section>

    <section id="demo" class="section">
        <div class="container">
            <h2>Try the Image Captioning Demo</h2>
            <p>Click below to upload an image and watch the magic happen!</p>
            <button class="btn" onclick="alert('Demo Feature Coming Soon!')">Upload an Image</button>
        </div>
    </section>

    <section id="future" class="section">
        <div class="container">
            <h2>Future Work</h2>
            <p>
                In future updates, the project will aim to integrate interactive features, such as real-time captioning, model tuning options, and a performance comparison interface to show the improvements made by the transformer models.
            </p>
            <a href="#contact" class="btn">Contact Us</a>
        </div>
    </section>

    <footer>
        <div class="container">
            <p>&copy; 2024 AI Image Captioning Project | Designed by Your Name</p>
        </div>
    </footer>

    <script>
        function showMore(model) {
            var moreText = document.getElementById(model);
            if (moreText.style.display === "none") {
                moreText.style.display = "block";
            } else {
                moreText.style.display = "none";
            }
        }
    </script>

</body>
</html>